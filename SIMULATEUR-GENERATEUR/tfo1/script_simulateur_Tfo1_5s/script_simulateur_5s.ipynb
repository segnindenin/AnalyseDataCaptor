{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m r16_tab1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39muser\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdeep_learning\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mMDMS\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDataCompters\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mR16\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mR16_alm_2022-11-15_19\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mR16_alm_2022-11-15.log\u001b[39;49m\u001b[39m'\u001b[39;49m, lines\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    611\u001b[0m \u001b[39mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 612\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\io\\json\\_json.py:744\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m         data \u001b[39m=\u001b[39m ensure_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    743\u001b[0m         data_lines \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 744\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_lines(data_lines))\n\u001b[0;32m    745\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    766\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 768\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m    770\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_numpy()\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 880\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_no_numpy()\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\deep_learning\\ANPR\\anprsys\\lib\\site-packages\\pandas\\io\\json\\_json.py:1133\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[0;32m   1131\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1133\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1135\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1136\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[0;32m   1137\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[0;32m   1138\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1139\u001b[0m     }\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r16_tab1 = pd.read_json('C:\\\\Users\\\\user\\\\deep_learning\\\\MDMS\\\\DataCompters\\\\R16\\\\R16_alm_2022-11-15_19\\\\R16_alm_2022-11-15.log', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r16_tab1=r16_tab1.loc[r16_tab1.type_mesure.isin(['courant', 'courant_hta', 'desequilibre_courant', \n",
    "                                                 'desequilibre_tension', 'tension_n', 'tension_ph',\n",
    "                                                 'tension_ph_hta'\n",
    "                                                 ])]\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_dictionnaire = {'courant': int(1), 'courant_hta': int(2), 'desequilibre_courant':int(3),  \n",
    "                    'tension_n':int(4), 'tension_ph':int(5), 'tension_ph_hta':int(6), \n",
    "                    'desequilibre_tension':int(7)}\n",
    "\n",
    "\n",
    "r16_tab1 = r16_tab1.set_index('date_heure_mesure')\n",
    "r16_tab1.index = pd.to_datetime(r16_tab1.index)\n",
    "\n",
    "\n",
    "def create_features(r16_tab1):\n",
    "            \"\"\"\n",
    "            Create time series features based on time series index.\n",
    "            \"\"\"\n",
    "            r16_tab1 = r16_tab1.copy()\n",
    "            r16_tab1['heure_mesure'] = r16_tab1.index.hour\n",
    "            r16_tab1['minute_mesure'] = (r16_tab1.index.minute)\n",
    "            r16_tab1['seconde_mesure'] = r16_tab1.index.second\n",
    "            # r16_tab1['depart'] =r16_tab1.depart\n",
    "            r16_tab1['type_mesure'] = r16_tab1.type_mesure\n",
    "            r16_tab1['phase'] = r16_tab1.phase\n",
    "            return r16_tab1\n",
    "\n",
    "for type_mesure, encoder in mon_dictionnaire.items():\n",
    "        # print(\"l'élément de clé\", type_mesure, \"vaut\", encoder)\n",
    "        r16_tab1_2 = r16_tab1.copy()\n",
    "\n",
    "        r16_tab1_2['type_mesure'] = r16_tab1_2['type_mesure'].map({\n",
    "                             type_mesure : encoder,\n",
    "                            \n",
    "                             },\n",
    "                             na_action=None)\n",
    "\n",
    "        r16_tab1_2['phase']= r16_tab1_2['phase'].replace(['N'],[4])\n",
    "        # set(r16_tab1.phase)\n",
    "        r16_tab1_2 = r16_tab1_2.dropna(subset='type_mesure')\n",
    "        r16_tab1_2['phase']=r16_tab1_2['phase'].astype(int)\n",
    "\n",
    "\n",
    "        train = r16_tab1_2\n",
    "        test = r16_tab1_2\n",
    "\n",
    "        r16_tab1_2 = create_features(r16_tab1_2)\n",
    "        train = create_features(train)\n",
    "        test = create_features(test)\n",
    "\n",
    "        FEATURES = ['type_mesure', 'phase', 'heure_mesure', 'minute_mesure', 'seconde_mesure']\n",
    "        TARGET = 'mesure'\n",
    "\n",
    "        X_train = train[FEATURES]\n",
    "        y_train = train[TARGET]\n",
    "\n",
    "        X_test = test[FEATURES]\n",
    "        y_test = test[TARGET]\n",
    "\n",
    "        reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                            n_estimators=10000,\n",
    "                            early_stopping_rounds=50,\n",
    "                            objective='reg:linear',\n",
    "                            max_depth=3,\n",
    "                            learning_rate=0.001)\n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                verbose=100)\n",
    "                \n",
    "        filename = f'r16_Tfo1_{type_mesure}'\n",
    "\n",
    "        with open(f'{filename}.pkl', \"wb\") as f:\n",
    "            pickle.dump(reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_dictionnaire = {'courant': int(1), 'courant_hta': int(2), 'desequilibre_courant':int(3),  \n",
    "                    'tension_n':int(4), 'tension_ph':int(5), 'tension_ph_hta':int(6), \n",
    "                    'desequilibre_tension':int(7)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r16_tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = r16_tab1.copy()\n",
    "\n",
    "test['type_mesure'] = test['type_mesure'].map({\n",
    "                             'courant' : int(1),                           \n",
    "                             },\n",
    "                             na_action=None)\n",
    "\n",
    "test['phase']= test['phase'].replace(['N'],[4])\n",
    "        # set(r16_tab1.phase)\n",
    "test = test.dropna(subset='type_mesure')\n",
    "test['phase']=test['phase'].astype(int)\n",
    "test = create_features(test)\n",
    "X_test = test[FEATURES]\n",
    "\n",
    "with open('r16_Tfo1_courant.pkl', \"rb\") as f:\n",
    "    reg = pickle.load(f)\n",
    "\n",
    "test['prediction'] = reg.predict(X_test)\n",
    "test.iloc[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voir_test = test.loc[(test['type_mesure'] == 1) & (test['phase'] == 1)]\n",
    "\n",
    "a = voir_test.index\n",
    "b = voir_test.prediction\n",
    "# c = voir_test.index\n",
    "# d = voir_test.prediction\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(3,1,1)\n",
    "plt.plot(a, b, c='yellow')\n",
    "# plt.plot(c,d, c='yellow')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r16_tab1 = r16_tab1.set_index('date_heure_mesure')\n",
    "# r16_tab1.index = pd.to_datetime(r16_tab1.index)\n",
    "\n",
    "def create_features(r16_tab1):\n",
    "            \"\"\"\n",
    "            Create time series features based on time series index.\n",
    "            \"\"\"\n",
    "            r16_tab1 = r16_tab1.copy()\n",
    "            r16_tab1['heure_mesure'] = r16_tab1.index.hour\n",
    "            r16_tab1['minute_mesure'] = (r16_tab1.index.minute)\n",
    "        #     r16_tab1['seconde_mesure'] = r16_tab1.index.second\n",
    "            r16_tab1['depart'] =r16_tab1.depart\n",
    "            r16_tab1['type_mesure'] = r16_tab1.type_mesure\n",
    "            r16_tab1['phase'] = r16_tab1.phase\n",
    "            return r16_tab1\n",
    "\n",
    "test = create_features(r16_tab1)\n",
    "\n",
    "FEATURES = ['depart', 'type_mesure', 'phase', 'heure_mesure', 'minute_mesure']\n",
    "TARGET = 'mesure'\n",
    "\n",
    "# X_train = train[FEATURES]\n",
    "# y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "with open('r16_tab1_tdh_tension.pkl', \"rb\") as f:\n",
    "    reg = pickle.load(f)\n",
    "\n",
    "test['prediction'] = reg.predict(X_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mere = test.copy()\n",
    "mere['laisse'] = 'seconde_mesure'\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_dictionnaire = {'courant': int(1), 'courant_hta': int(2), 'desequilibre_courant':int(3),  \n",
    "                    'tension_n':int(4), 'tension_ph':int(5), 'tension_ph_hta':int(6), \n",
    "                    'desequilibre_tension':int(7)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r16_tab1.loc[r16_tab1['type_mesure']== 'tdh_courant'].drop_duplicates(subset='depart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r16_tab1.loc[(r16_tab1['type_mesure'] == 'tdh_courant')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt= r16_tab1.copy\n",
    "bt\n",
    "bt['type_mesure'].loc[bt['type_mesure']== 1] = eng.predict(bt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "a = [[1,2,3,4,5,6,7],[1,2,3,4]]\n",
    "famille = list(itertools.product(*a))\n",
    "\n",
    "my_data = []\n",
    "for i in famille:\n",
    "    my_data.append(list(i))\n",
    "\n",
    "my_data = np.array(my_data)\n",
    "\n",
    "column_names = [\"type_mesure\", \"phase\"]\n",
    "data_df = pd.DataFrame(my_data, columns=column_names)\n",
    "data = data_df.drop(data_df.loc[(data_df['type_mesure'].isin([2,4,5,6,7])) & (data_df['phase'].isin([4]))].index)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "hr = int(datetime.datetime.now().strftime(\"%H\"))\n",
    "mn = int(datetime.datetime.now().strftime(\"%M\"))\n",
    "sd = int(datetime.datetime.now().strftime(\"%S\"))\n",
    "da_hr_ms = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    " \n",
    "data['heure_mesure'] = hr\n",
    "data['minute_mesure'] = mn\n",
    "data['seconde_mesure'] = sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_dictionnaire = {'courant': int(1), 'courant_hta': int(2), 'desequilibre_courant':int(3),  \n",
    "                    'tension_n':int(4), 'tension_ph':int(5), 'tension_ph_hta':int(6), \n",
    "                    'desequilibre_tension':int(7)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('r16_Tfo1_courant.pkl', \"rb\") as a:\n",
    "    crt = pickle.load(a)\n",
    "with open('r16_Tfo1_courant_hta.pkl', \"rb\") as b:\n",
    "    crt_hta = pickle.load(b)\n",
    "with open('r16_Tfo1_desequilibre_courant.pkl', \"rb\") as c:\n",
    "    des_crt = pickle.load(c)\n",
    "with open('r16_Tfo1_tension_n.pkl', \"rb\") as d:\n",
    "    ten = pickle.load(d)\n",
    "with open('r16_Tfo1_tension_ph.pkl', \"rb\") as e:\n",
    "    ten_ph = pickle.load(e)\n",
    "with open('r16_Tfo1_tension_ph_hta.pkl', \"rb\") as f:\n",
    "    ten_ph_hta = pickle.load(f)\n",
    "with open('r16_Tfo1_desequilibre_tension.pkl', \"rb\") as g:\n",
    "    des_ten = pickle.load(g)\n",
    "\n",
    "\n",
    "data_omo = data.copy()\n",
    "\n",
    "data['type_mesure'].loc[data['type_mesure']==1] = crt.predict(data_omo.loc[data['type_mesure']==1])\n",
    "data['type_mesure'].loc[data['type_mesure']==2] = crt_hta.predict(data_omo.loc[data_omo['type_mesure']== 2])\n",
    "data['type_mesure'].loc[data['type_mesure']==3] = des_crt.predict(data_omo.loc[data_omo['type_mesure']== 3])\n",
    "data['type_mesure'].loc[data['type_mesure']==4] = ten.predict(data_omo.loc[data_omo['type_mesure']== 4])\n",
    "data['type_mesure'].loc[data['type_mesure']==5] = ten_ph.predict(data_omo.loc[data_omo['type_mesure']== 5 ])\n",
    "data['type_mesure'].loc[data['type_mesure']==6] = ten_ph_hta.predict(data_omo.loc[data_omo['type_mesure']== 6 ])\n",
    "data['type_mesure'].loc[data['type_mesure']==7] = des_ten.predict(data_omo.loc[data_omo['type_mesure']== 7 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mesure'] = data['type_mesure']\n",
    "data['type_mesure'] = data_omo['type_mesure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['type_mesure'] = data['type_mesure'].map({\n",
    "                             1:'courant',\n",
    "                             2:'courant_hta',\n",
    "                             3:'desequilibre_courant',\n",
    "                             4:'tension_n',\n",
    "                             5:'tension_ph',\n",
    "                             6:'tension_ph_hta',\n",
    "                             7:'desequilibre_tension',                    \n",
    "                             },\n",
    "                             na_action=None)\n",
    "\n",
    "data['phase']= data['phase'].replace([4],['N'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_heure_mesure'] = da_hr_ms\n",
    "data = data.drop(columns=['heure_mesure', 'minute_mesure', 'seconde_mesure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['id_poste'] = 'P0016.210.043'\n",
    "data['zone_poste'] = 'transfo1'\n",
    "data['classification'] = 'CLA_BT'\n",
    "data['classification'].loc[data['type_mesure'].isin(['tension_ph_hta', 'courant_hta'])] = 'CLA_HTA'\n",
    "data['date_heure_transfert'] = da_hr_ms\n",
    "data['unite_mesure'] = data['type_mesure']\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['energie'])] = 'MWh'\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['frequence'])] = 'Hz'\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['puissance_active'])] = 'W'\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['puissance_apparente'])] = 'VA'\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['puissance_reactive'])] = 'VAR'\n",
    "data['unite_mesure'].loc[data['unite_mesure'].isin(['facteur_puissance', 'taux_de_charge', 'tdh_courant', 'tdh_tension'])] = '%'\n",
    "# data['phase'] = data['phase'].astype(int)\n",
    "data['phase'] = data['phase'].astype(str)\n",
    "data['description_mesure'] = 'mesure - ' + data['type_mesure'] + ' phase ' +  data['phase']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\n",
    "    'id_poste', 'zone_poste', 'classification', \n",
    "    'type_mesure', 'description_mesure', 'phase', 'mesure',\n",
    "    'unite_mesure', 'date_heure_mesure','date_heure_transfert'\n",
    "    ]]\n",
    "    \n",
    "data_log = data.to_json(orient = 'records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_name = 'R16_Tab1_{}.log'.format(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "file = open(files_name, \"a+\")\n",
    "file.write(data_log)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[(test['type_mesure']==1) & (test['depart']==2)].iloc[0:60]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('anprsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe91e35d0711380e9b5a44415c8c501d6a038128fd955737e793fcbbc8049f8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
